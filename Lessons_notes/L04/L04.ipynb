{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L04 14/03/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of n features, the goal of feature selection is to select a subset of d features $(d<n)$ in order to minimize the classification error  \n",
    "It's a dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why would we do that?\n",
    "- data interpreation is easier, it's more explainable\n",
    "- reduced data dimensionality helps with the computational effort, when classifying novel patterns, only a small number of features need to be computed (faster classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection is an optimization process\n",
    "- **Step 1**: search the space of possible feature subsets\n",
    "- **Step 2**: pick the subset that is optimal or near-optimal with respect so some objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search strategy\n",
    "- **Exhaustive research**: assuming n features, an exhaustive reseach would take too long\n",
    "- **Naive search**:\n",
    "  - Sort given n features in order of their probability of correct recognition (**statistical significance**)\n",
    "  - select the top d features from this sorted list\n",
    "  - Disadvantage: Correlation among features is not considered, and the best pair of features may not even contain the best individual feature\n",
    "- **Sequential forward selection (SFS)**:\n",
    "  - First, the best single feature is selected (using some cretion function)\n",
    "  - Then, pairs of features are formed using one of the remaining features and this best feasture, and the best pair is selected\n",
    "  - Next, \n",
    "- **Sequential backwards selection (SBS)**\n",
    "- **Bidirectional Search (BDS)**\n",
    "\n",
    "*for the project, eliminate all the correlated features that have low entropy*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There exists 4 main approaches\n",
    "- Undersampling:\n",
    "  - If we have 100% of class 4, and 10% of class 43, I eliminate 90% of  class 4 in order to have 10%, and 10%\n",
    "- Oversampling\n",
    "  - I use the original 100% of class 3, but I need to oversample the 10% of class 4, I need to create synthetic data (SMOTE in python)\n",
    "- Generation of synthetic data\n",
    "- Cost-sensitive (CS) learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
